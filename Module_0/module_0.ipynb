{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 0: Simple RAG with LangSmith Tracing\n",
        "\n",
        "This personalized notebook sets up a small RAG app using LangSmith docs and adds tracing configured to your own project. Replace placeholders below with your keys if not using a `.env`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tracing: true Project: nischala-personal-project\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Inline env (optional). Prefer .env in project root.\n",
        "os.environ.setdefault(\"LANGSMITH_TRACING\", \"true\")\n",
        "os.environ.setdefault(\"LANGSMITH_PROJECT\", \"Langsmith_intro\")  # personalize project name\n",
        "os.environ.setdefault(\"GEMINI_API_KEY\", os.getenv(\"GEMINI_API_KEY\", \"\"))\n",
        "os.environ.setdefault(\"LANGSMITH_API_KEY\", os.getenv(\"LANGSMITH_API_KEY\", \"\"))\n",
        "\n",
        "# Load from .env if present\n",
        "load_dotenv(dotenv_path=\"../../.env\", override=True)\n",
        "print(\"Tracing:\", os.getenv(\"LANGSMITH_TRACING\"), \"Project:\", os.getenv(\"LANGSMITH_PROJECT\"))\n",
        "\n",
        "# Install Gemini client if needed\n",
        "try:\n",
        "    import google.generativeai as genai  # noqa: F401\n",
        "except Exception:\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"google-generativeai\", \"-q\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Personalized RAG application\n",
        "from langsmith import traceable\n",
        "from typing import List\n",
        "import nest_asyncio\n",
        "\n",
        "# Reuse utils retriever from module_0\n",
        "import sys\n",
        "sys.path.append(\"../notebooks/module_0\")\n",
        "from utils import get_vector_db_retriever\n",
        "\n",
        "# Gemini setup\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\", \"\"))\n",
        "MODEL_PROVIDER = \"google\"\n",
        "MODEL_NAME = \"models/gemini-2.5-flash\"\n",
        "APP_VERSION = 1.0\n",
        "RAG_SYSTEM_PROMPT = (\n",
        "    \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the latest question in the conversation. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\"\n",
        ")\n",
        "\n",
        "nest_asyncio.apply()\n",
        "retriever = get_vector_db_retriever()\n",
        "\n",
        "@traceable(run_type=\"retriever\", metadata={\"owner\": \"Nischala\", \"vectordb\": \"sklearn\"})\n",
        "def retrieve_documents(question: str):\n",
        "    return retriever.invoke(question)\n",
        "\n",
        "@traceable(run_type=\"chain\", metadata={\"app_version\": APP_VERSION})\n",
        "def generate_response(question: str, documents):\n",
        "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": RAG_SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"},\n",
        "    ]\n",
        "    return call_gemini(messages)\n",
        "\n",
        "@traceable(run_type=\"llm\", metadata={\"ls_provider\": MODEL_PROVIDER, \"ls_model_name\": MODEL_NAME})\n",
        "def call_gemini(messages: List[dict]):\n",
        "    # Convert OpenAI-like messages to a single prompt for Gemini\n",
        "    prompt = \"\\n\\n\".join([m[\"content\"] for m in messages])\n",
        "    model = genai.GenerativeModel(MODEL_NAME)\n",
        "    resp = model.generate_content(prompt)\n",
        "    class Obj:  # minimal adapter to keep downstream code unchanged\n",
        "        class ChoicesMsg:\n",
        "            def __init__(self, content):\n",
        "                self.message = type(\"Msg\", (), {\"content\": content})\n",
        "        def __init__(self, text):\n",
        "            self.choices = [self.ChoicesMsg(text)]\n",
        "    return Obj(resp.text)\n",
        "\n",
        "@traceable(run_type=\"chain\")\n",
        "def langsmith_rag(question: str):\n",
        "    documents = retrieve_documents(question)\n",
        "    response = generate_response(question, documents)\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith is a platform designed for product engineers to build and manage production-grade LLM applications. It allows you to monitor, trace, and evaluate your applications to ensure quality and reliability. Additionally, it offers tools to test prompts, providing automatic version control and collaboration features for faster iteration.\n"
          ]
        }
      ],
      "source": [
        "# Try it\n",
        "question = \"What is LangSmith used for? Answer for a product engineer.\"\n",
        "ai_answer = langsmith_rag(question)\n",
        "print(ai_answer)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv-langsmith",
      "language": "python",
      "name": "venv-langsmith"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
